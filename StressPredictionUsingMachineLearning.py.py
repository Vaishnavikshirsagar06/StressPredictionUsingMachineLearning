# -*- coding: utf-8 -*-
"""Another copy of Untitled12.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oxN2cngcjUblZgJYadHtgwtmlhKBzUFp
"""

import numpy as np
import pandas as pd

df = pd.read_csv("Stress.csv")
df.head()

df.describe()

df.isnull().sum()

import nltk
import re
from nltk.corpus import stopwords
import string
nltk.download('stopwords')
stemmer = nltk.SnowballStemmer("english")
stopword = set(stopwords.words('english'))

def clean(text):
    text = str(text).lower()  #returns a string where all characters are lower case. Symbols and Numbers are ignored.
    text = re.sub('\[.*?\]', ' ', text)  #substring and returns a string with replaced values.
    text = re.sub('https?://\S+/www\. \S+', ' ', text)  #whitespace char with pattern
    text = re.sub('<. *?>+', ' ', text)  #special char enclosed in square brackets
    text = re.sub(' [%s]' % re.escape(string.punctuation), ' ', text)  #eliminate punctuation from string
    text = re.sub(' \n', ' ', text)
    text = re.sub(' \w*\d\w*', ' ', text)  #word character ASCII punctuation
    text = [word for word in text.split(' ') if word not in stopword]  #removing stopwords
    text = " ".join(text)
    text = [stemmer.stem(word) for word in text.split(' ')]  #remove morphological affixes from words
    text = " ".join(text)
    return text

df["text"] = df["text"].apply(clean)

# The following line was causing the error due to unexpected indentation
# It should be aligned with the other import statements
!pip install wordcloud
import matplotlib.pyplot as plt
from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator
text = " ".join(i for i in df.text)
stopwords = set(STOPWORDS)
wordcloud = WordCloud(stopwords=stopwords, background_color="white").generate(text)
plt.figure(figsize=(10, 10))
plt.imshow(wordcloud)
plt.axis("off")
plt.show()

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split

x = np.array(df["text"])
y = np.array(df["label"])

cv = CountVectorizer()
X = cv.fit_transform(x)
print(X)
xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.33)

from sklearn.naive_bayes import BernoulliNB
model = BernoulliNB()
model.fit(xtrain, ytrain)

user = input("Enter the text")
data = cv.transform([user]).toarray()
output = model.predict(data)
print(output)

if (output == 1):
  print("Stress")
else:
  print("No Stress")
  import random

stress_recommendations = {
    "deep_breathing": "Try deep breathing exercises for 5 minutes.",
    "mindfulness": "Practice mindfulness meditation for 10 minutes.",
    "music": "Listen to calming music.",
    "break": "Take a short break and step away from your work."
}
import random

jokes = [
    "Why don't scientists trust atoms? Because they make up everything!",
    "What do you call a lazy kangaroo? A pouch potato!",
    "Parallel lines have so much in common. It's a shame they'll never meet.",
    # Add more jokes here...
]

import numpy as np
import pandas as pd
# Use 'output' instead of 'prediction' in the condition
if output == 1:  # 1 represents "Stress" in your model's output
    joke = random.choice(jokes)
    # Assumed you have imported streamlit as st for st.write to work
    # If not, replace st.write with print
    print("Here's a joke to lighten the mood:\n", joke)
# Use 'output' instead of 'prediction' in the condition
if output == 1:  # 1 represents "Stress" in your model's output
    recommendation = random.choice(list(stress_recommendations.values()))
    # Assumed you have imported streamlit as st for st.write to work
    # If not, replace st.write with print
    print("Recommendation:", recommendation)

import numpy as np
import pandas as pd

from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, accuracy_score # Import accuracy_score
# After training the model:
y_pred = model.predict(xtest)
accuracy = accuracy_score(ytest, y_pred)

# Calculate and store F1 score, recall, and precision
f1 = f1_score(ytest, y_pred)
recall = recall_score(ytest, y_pred)
precision = precision_score(ytest, y_pred)

# Calculate the confusion matrix and assign it to conf_matrix
conf_matrix = confusion_matrix(ytest, y_pred)
percentage_accuracy = accuracy * 100  # Convert to percentage
print("Accuracy:", percentage_accuracy, "%")
# Print metrics
print("Confusion Matrix:\n", conf_matrix)
print("F1 Score:", f1*100) # Now f1, recall, and precision are defined
print("Recall:", recall*100)
print("Precision:", precision*100)

import seaborn as sns
import matplotlib.pyplot as plt

# After calculating the confusion matrix
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues") # Now conf_matrix is defined
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()



